# Using Cluster Logging Forwarder on GCP with Google Cloud Operations (formerly Stackdriver)

**Thatcher Hubbard**

*10/13/2022*

The native OpenShift Logging Operator is easy to set up in terms of pushing logs to an in-cluster Elasticsearch/Grafana, but for OSD users on GCP, it might be preferrable to use the native logging/monitoring/tracing facility: [Stackdriver](https://cloud.google.com/products/operations).

There's a number of ways to do this, for example installing agents onto the VMs (in this case, it would be a DaemonSet with hostvar mounts) but that isn't ideal in a managed system like OSD.

Until recently, the Logging Operator didn't have the capability to write directly to Stackdriver because the underlying logging agent (FluentD) didn't support it. As of release 5.5.3 however, the Logging Operator can now use [Vector](https://vector.dev/) as a logging agent, and Vector can write to Stackdriver.

## Prepare your OSD cluster

1. [Deploy](https://docs.openshift.com/dedicated/osd_install_access_delete_cluster/creating-a-gcp-cluster.html#osd-create-gcp-cluster-ccs_osd-creating-a-cluster-on-gcp) an OSD cluster on GCP

1. Configure the necessary IdP on the cluster for login, and get a login token via the console so that an `oc login` can be run to establish CLI access.

## Install Requried Operators

This configuration will need CRDs provided by the Red Hat Logging Operator.

Operators can be installed via the 'OperatorHub' in the OCP console, or directly via the API:

   ```bash
   cat << EOF | oc apply -f -
   apiVersion: operators.coreos.com/v1alpha1
   kind: Subscription
   metadata:
     labels:
      operators.coreos.com/cluster-logging.openshift-logging: ""
     name: cluster-logging
     namespace: openshift-logging
   spec:
     channel: stable
     installPlanApproval: Automatic
     name: cluster-logging
     source: redhat-operators
     sourceNamespace: openshift-marketplace
     startingCSV: cluster-logging.5.5.3
   EOF
   ```

## Create IAM Credentials

1. The first step is to create a Service Account. This can be done via the web console inder the 'IAM | Service Accounts' dialog. If you have multiple OSD clusters in the project, you may want to give each cluster it's own service account for this purpose, in which case you'd want to account name to reflect the name or id of the cluster. It's also fine to use something generic like `osd-stackdriver-logging`.

After naming and creating the Service Account, the option to grant access to the project is presented, and only one pre-defined role should be needed here: 'Logs Writer'.

This should return to the service account list for the project. Select the newly created service account for the next step.

1. The next step is to generate a key that can be used as credentials for this account. If the service account is selected and the 'Details' screen is being shown, the 'Keys' tab can be clicked on to start this process.

A button labelled 'Add Key' is below, click it and then select 'Add New Key', and select the 'JSON' option when given the option. This will download a file to the local workstation that contains the key. In a development environment (which is typically where you'd use this configuration), it may be a good idea to save the contents of the key in GCP Secret Manager if an entire team might need to share it. There's a limit of 10 keys assigned to any one service account, and no real way to associate them a specific OSD cluster, so it's possible to have 10 unknown keys and no room to create a new one without deleting an existing.


1. Create a Secret to hold the GCP IAM creds:

```bash
oc -n openshift-logging create secret generic stackdriver-logging-creds --from-file=google-application-credentials.json=<path_to_json_file>
```

> Note the `google-application-credentials.json` is required to be the key in the Secret because while the Secret name can be anything you like, the key becomes the file path when it's mounted in the Vector Pod, and the Vector configuration generated by the Operator looks specifically for that filename.

1. Set some environment variables:

  ```bash
  export CLUSTER_NAME=<my_cluster>
  export PROJECT_ID=<gcp_project_id>
  ```

1. Configure the ClusterLoggingForwarder:

  ```bash
  cat << EOF | oc apply -f -
  apiVersion: logging.openshift.io/v1
  kind: ClusterLogForwarder
  metadata:
    name: instance
    namespace: openshift-logging
  spec:
    outputs:
      - googleCloudLogging:
          logId: th-test
          projectId: mobb-demo
        name: stackdriver
        secret:
          name: stackdriver-logging-creds
        type: googleCloudLogging
    pipelines:
      - inputRefs:
          - application
          - audit
          - infrastructure
        name: to-stackdriver
        outputRefs:
          - stackdriver
  EOF
  ```

1. Configure the ClusterLogging resource:

  ```bash
  cat << EOF | oc apply -f -
  apiVersion: logging.openshift.io/v1
  kind: ClusterLogging
  metadata: 
    name: instance
    namespace: openshift-logging
  spec: 
    collection: 
      logs: 
        type: vector
        vector: {}
  forwarder: 
    managementState: Managed
  EOF
  ```

1. Check Google Cloud Logging for logs

